{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRABAJO FINAL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import category_encoders as ce\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import metrics, neighbors, tree, preprocessing\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from matplotlib.colors import ListedColormap\n",
    "from shutil import copyfile\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score \n",
    "from sklearn.metrics import auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import math \n",
    "import category_encoders as ce\n",
    "from sklearn import pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import feature_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEMA 3: METRICAS RENDIMIENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtenerMatrizConfusion(clasificador, X, y):\n",
    "    # Habra que ajustar labels al numero de clases que tengamos\n",
    "    matrizConfusion = confusion_matrix(y,clasificador.predict(X), labels= [1,0])\n",
    "    return matrizConfusion\n",
    "\n",
    "def calidad_modelo(clf, X,y):\n",
    "    y_pred = clf.predict(X)\n",
    "    recall_medio_clf = roc_auc_score(y, y_pred)*100\n",
    "    tpr_clf = recall_score(y,y_pred, pos_label=1)\n",
    "    tnr_clf = recall_score(y,y_pred, pos_label=0)\n",
    "    gm_clf = math.sqrt(tpr_clf*tnr_clf)*100\n",
    "    fscore_clf = f1_score(y,y_pred)*100\n",
    "    return recall_medio_clf,gm_clf, fscore_clf\n",
    "\n",
    "def resumenMedidasRendimient(clasificador, X,y):\n",
    "    return classification_report(y,clasificador.predict(X))\n",
    "\n",
    "# labels debe ser un listado con los nombres de los clasificadores.\n",
    "def muestra_ROC_courve(listaClfs, X, y, labels):\n",
    "    # generamos una predicción sin calidad para la clase positiva (1): todas las predicciones con probabilidad 0\n",
    "    ns_probs = np.zeros(len(y))\n",
    "    # calculamos el área bajo la curva ROC (método roc_auc_score pasando las clases reales y las probabilidades de la clase positiva)\n",
    "        # En tanto por 100\n",
    "    ns_auc = roc_auc_score(y,ns_probs)*100\n",
    "    # calculamos todos los pares de puntos (fpr, tpr) para dibujar la curva ROC (método roc_curve pasando las clases reales y las probabilidades de la clase positiva)\n",
    "    ns_fpr, ns_tpr, _ = roc_curve(y,ns_probs)\n",
    "    \n",
    "    # Lista para almacenar los AUC bajo la curva ROC de los clasificadores\n",
    "    listaAUCs = []\n",
    "    # Para cada clasificador de la lista\n",
    "    for i,clf in enumerate(listaClfs):\n",
    "        # predecimos las probabilidades de predecir cada ejemplo en cada clase en base al método que implemente el clasificador\n",
    "        if hasattr(clf, 'predict_proba'):\n",
    "            # Si el clasificador implementa predict_proba nos quedamos con las predicciones de la clase positiva (1)\n",
    "            model_probs = clf.predict_proba(X)[:,1]\n",
    "        else:\n",
    "            # Si el clasificador implementa decision_function\n",
    "            model_probs = clf.decision_function(X)\n",
    "\n",
    "        # calculamos todos los pares de puntos (fpr, tpr) para dibujar la curva ROC (método roc_curve pasando las clases reales y las probabilidades de la clase positiva)\n",
    "        model_fpr, model_tpr, _ = roc_curve(y,model_probs)\n",
    "        # calculamos el área bajo la curva ROC, y lo añadimos a la lista de rendimiento, en tanto por 100\n",
    "        model_auc = roc_auc_score(y,model_probs)*100\n",
    "        listaAUCs.append(model_auc)\n",
    "        # Mostramos visualmente la curva ROC (plot mostrando fpr en el eje x y tpr en el eje y) poniendo como etiqueta el nombre del clasificador\n",
    "        plt.figure()\n",
    "        plt.title(labels[i])\n",
    "        plt.plot(model_fpr,model_tpr)\n",
    "        \n",
    "    # mostramos la curva del modelo sin calidad\n",
    "    plt.figure()\n",
    "    plt.plot(ns_fpr,ns_tpr)\n",
    "    # Etiquetamos los ejes\n",
    "    plt.xlabel(\"fpr\")\n",
    "    plt.ylabel(\"tpr\")\n",
    "    # Creamos la leyenda de la figura\n",
    "    plt.legend()\n",
    "    # Ponemos título a la figura\n",
    "    plt.title(\"Modelo sin calidad\")\n",
    "    # Mostramos la figura\n",
    "    # <RELLENAR>\n",
    "    # Devolvemos la lista con los AUC de los diferentes clasificadores\n",
    "    return listaAUCs\n",
    "\n",
    "\n",
    "# labels debe ser un listado con los nombres de los clasificadores.\n",
    "def muestra_PR_courve(listaClfs, X, y, labels):\n",
    "    # Calculamos lo necesario para mostrar la curva PR y sus valores de rendimiento\n",
    "        # Predicción sin calidad para todos los ejemplos (proporción de ejemplos de la clase positiva, 1) \n",
    "    no_skill = np.zeros(len(y))\n",
    "    precision,recall,_=precision_recall_curve(y,no_skill)\n",
    "    plt.figure()\n",
    "    plt.title(\"Sin calidad\")\n",
    "    plt.plot(precision,recall)\n",
    "    plt.xlabel(\"precision\")\n",
    "    plt.xlabel(\"recall\")\n",
    "    # Para cada clasificador de la lista\n",
    "    rendimientos = []\n",
    "    for i,clf in enumerate(listaClfs):\n",
    "        if hasattr(clf, 'predict_proba'):\n",
    "            # Si el clasificador implementa predict_proba nos quedamos con las predicciones de la clase positiva (1)\n",
    "            model_probs = clf.predict_proba(X)[:,1]\n",
    "        else:\n",
    "            # Si el clasificador implementa decision_function\n",
    "            model_probs = clf.decision_function(X)\n",
    "        precision, recall,_ = precision_recall_curve(y,model_probs)\n",
    "        plt.figure()\n",
    "        plt.title(labels[i])\n",
    "        plt.plot(precision,recall, label = \"PR\")\n",
    "        plt.xlabel(\"precision\")\n",
    "        plt.xlabel(\"recall\")\n",
    "        plt.legend()\n",
    "        rendimientos.append(auc(recall,precision)*100)\n",
    "    return rendimientos\n",
    "\n",
    "\n",
    "# Función que muestra el compromiso entre precision y recall para un clasificador (clf) y unos datos de entrada (X) y salida (y)\n",
    "def muestra_balance_PR(clf, X, y):\n",
    "    # Obtenemos las probabilidades de la clase positiva\n",
    "    model_probs = clf.predict_proba(X)[:,1]\n",
    "    \n",
    "    # Obtenemos los umbrales que se generan y que caracterizan la curva PR (usar método precision_recall_curve)\n",
    "    model_precision, model_recall, umbrales = precision_recall_curve(y,model_probs)\n",
    "    # Añadimos 1 como umbral para que la gráfica vaya hasta dicho punto (el par PR ya está calculado)\n",
    "    umbrales = np.insert(umbrales, umbrales.size, 1., axis=0)\n",
    "    # Mostramos la figura: la precisión en rojo y el recall en azul\n",
    "    plt.figure()\n",
    "    plt.title(\"Balance precision-recall\")\n",
    "    plt.plot(model_precision,model_recall)\n",
    "    plt.xlabel(\"precision\")\n",
    "    plt.xlabel(\"recall\")\n",
    "\n",
    "    \n",
    "def clasificacion_umbral(probs_clase_positiva, umbral=0.5):\n",
    "    salida = []\n",
    "    for i in probs_clase_positiva:\n",
    "        if i > umbral:\n",
    "            salida.append(1)\n",
    "        else:\n",
    "            salida.append(0)\n",
    "    return salida\n",
    "\n",
    "def calcular_mejor_umbral_fscore(model, X_train, y_train, X_val, y_val):    \n",
    "    # predecimos las probabilidades de predecir cada ejemplo de train y de validación en la clase positiva\n",
    "    model_probs = model.predict_proba(X_train)[:,1]\n",
    "    model_probs_val =  model.predict_proba(X_val)[:,1]\n",
    "    \n",
    "    # calculamos todos los pares de puntos (recall, precision) y sus umbrales (método precision_recall_curve)\n",
    "    model_precision, model_recall, umbrales = precision_recall_curve(y_train,model_probs)\n",
    "    # Evaluamos el Fscore (método f1_score) de cada umbral \n",
    "    rendimiento_umbrales = []\n",
    "    indiceMejorUmbral = 0\n",
    "    max_fscore = 0\n",
    "    for i,umbral in enumerate(umbrales):\n",
    "        fscore = evaluar_mejor_umbral_fscore(model,umbral,X_val,y_val)\n",
    "        rendimiento_umbrales.append(fscore)\n",
    "        if (fscore > max_fscore):\n",
    "            indiceMejorUmbral = i\n",
    "            mejorUmbral = umbral\n",
    "            max_fscore = fscore \n",
    "    # Se consigue el índice del umbral que da mayor rendimiento\n",
    "#     indiceMejorUmbral = <RELLENAR>\n",
    "    # Se consigue el valor del mejor umbral\n",
    "#     mejorUmbral = <RELLENAR>\n",
    "    print('Mejor umbral={:.3f}, Fscore en validacion={:.2f}'.format(mejorUmbral, rendimiento_umbrales[indiceMejorUmbral]))\n",
    "    # Se devuelve el mejor umbral\n",
    "    return mejorUmbral\n",
    "\n",
    "def evaluar_mejor_umbral_fscore(model, umbral, X, y):\n",
    "    # Evaluamos la calidad del mejor umbral con los ejemplos\n",
    "    prediccion = model.predict_proba(X)[:,1]\n",
    "    model_probs = clasificacion_umbral(prediccion, umbral)\n",
    "    fscore = f1_score(y,model_probs)\n",
    "    return fscore*100\n",
    "\n",
    "def calcular_mejor_umbral_AUC_ROC(model, X_train, y_train, X_val, y_val):    \n",
    "    # predecimos las probabilidades de predecir cada ejemplo de train y de validación en la clase positiva\n",
    "    model_probs = model.predict_proba(X_train)[:,1]\n",
    "    model_probs_val =  model.predict_proba(X_val)[:,1]\n",
    "    \n",
    "    # calculamos todos los pares de puntos (recall, precision) y sus umbrales (método precision_recall_curve)\n",
    "    model_precision, model_recall, umbrales = roc_curve(y_train,model_probs)\n",
    "\n",
    "    # Evaluamos el Fscore (método f1_score) de cada umbral \n",
    "    rendimiento_umbrales = []\n",
    "    indiceMejorUmbral = 0\n",
    "    max_auc_roc = 0\n",
    "    \n",
    "    for i,umbral in enumerate(umbrales):\n",
    "        auc_roc = evaluar_mejor_umbral_AUC_ROC(model,umbral,X_val,y_val)\n",
    "        rendimiento_umbrales.append(auc_roc)\n",
    "        if (auc_roc > max_auc_roc):\n",
    "            indiceMejorUmbral = i\n",
    "            mejorUmbral = umbral\n",
    "            max_auc_roc = auc_roc \n",
    "    # Se consigue el índice del umbral que da mayor rendimiento\n",
    "#     indiceMejorUmbral = <RELLENAR>\n",
    "    # Se consigue el valor del mejor umbral\n",
    "#     mejorUmbral = <RELLENAR>\n",
    "    print('Mejor umbral={:.3f}, AUC en validacion={:.2f}'.format(mejorUmbral, rendimiento_umbrales[indiceMejorUmbral]))\n",
    "    # Se devuelve el mejor umbral\n",
    "    return mejorUmbral\n",
    "\n",
    "def evaluar_mejor_umbral_AUC_ROC(model, umbral, X, y):\n",
    "    prediccion = model.predict_proba(X)[:,1]\n",
    "    model_probs = clasificacion_umbral(prediccion, umbral)\n",
    "    auc_roc = roc_auc_score(y,model_probs)\n",
    "    return auc_roc*100\n",
    "\n",
    "\n",
    "def tunearClasificador(clf, dic, metrica_rendimiento, X,y):\n",
    "    np.random.seed(12)\n",
    "    validacionCruzada = model_selection.StratifiedKFold(n_splits=5)\n",
    "    grid = GridSearchCV(clf, param_grid= dic,scoring=metrica_rendimiento, cv = validacionCruzada,return_train_score=True)\n",
    "    grid.fit(X,y)\n",
    "    resultadosMostrar = zip(grid.cv_results_['params'],grid.cv_results_['mean_test_score'],grid.cv_results_['mean_train_score'])\n",
    "    for params, mean_test_score, mean_train_score in resultadosMostrar:\n",
    "        print(\"%0.3f (Train: %0.3f) for %r\" % (mean_test_score, mean_train_score, params))\n",
    "        print()\n",
    "\n",
    "    return grid.best_estimator_, grid.best_score_, grid.best_params_\n",
    "\n",
    "# Esto es un ejmplo: \n",
    "score_PR = make_scorer(average_precision_score,needs_threshold=True)\n",
    "LR = LogisticRegression()\n",
    "grid_LR = {'C': [0.1,1,3,6,10]}\n",
    "bestLR_PR, best_val, best_hipPar = tunearClasificador(LR,grid_LR,score_PR,X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEMA 4: IMPUTACION DE MISSING VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocesamiento = ColumnTransformer(transformers=((\"media\", SimpleImputer(strategy='mean') , nombres_variables_numericas), \n",
    "                                                    (\"moda\", SimpleImputer(strategy='most_frequent'), nombres_variables_categoricas)))\n",
    "\n",
    "autos_sin_missing = preprocesamiento.fit_transform(autos_sin_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos la transformación utilizando la codificación ordinal\n",
    "ordinalEncoder = ce.OrdinalEncoder(cols = None)\n",
    "autos_ord = ordinalEncoder.fit_transform(autos_ord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos la transformación utilizando la codificación del conteo\n",
    "autos_count = autos_sin_missing.copy()\n",
    "\n",
    "countEncoder = ce.CountEncoder(cols = None)\n",
    "autos_count = countEncoder.fit_transform(autos_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos la transformación utilizando la codificación One Hot\n",
    "autos_oh = autos_sin_missing.copy()\n",
    "\n",
    "oneHotEncoder = ce.OneHotEncoder(cols = None)\n",
    "autos_oh = oneHotEncoder.fit_transform(autos_oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos la transformación utilizando la codificación binaria\n",
    "autos_binary = autos_sin_missing.copy()\n",
    "\n",
    "ordinalEncoder = ce.OrdinalEncoder(cols = nombres_variables_categoricas)\n",
    "binaryEncoder = ce.BinaryEncoder(cols = nombres_variables_categoricas)\n",
    "\n",
    "autos_binary = ordinalEncoder.fit_transform(autos_binary)\n",
    "autos_binary = binaryEncoder.fit_transform(autos_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos la transformación utilizando la codificación basada en la salida \n",
    "autos_te = autos_sin_missing.copy()\n",
    "salidas_te = autos_output.copy()\n",
    "\n",
    "targetEncoder = ce.TargetEncoder(smoothing=0.0000001)\n",
    "salidas_te = pd.DataFrame(autos_output, columns = ['price'])\n",
    "salidas_te = salidas_te.set_index(autos_te.index)\n",
    "\n",
    "autos_te = targetEncoder.fit_transform(autos_te, salidas_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de pipeline  + Grid search: \n",
    "pipe = pipeline.Pipeline([('codificacion ordinal ', ce.OrdinalEncoder(cols = nombres_variables_categoricas)), ('estandarizacion', MinMaxScaler()), ('knn', KNeighborsRegressor()) ])\n",
    "hiperParameters =  {\n",
    "    \"modelo__n_neighbors\": [3,5,7,9],\n",
    "    \"modelo__weights\": ['uniform','distance'],\n",
    "    \"modelo__p\":[1,2,1.5,3]\n",
    "}\n",
    "ss = model_selection.ShuffleSplit(n_splits = 1, test_size= 0.2)\n",
    "gridSearch_pipeline = model_selection.GridSearchCV(pipe, hiperParameters,cv=ss, return_train_score=True, scoring='neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clasificar las variables categoricas segun el numero de valores que toman.\n",
    "\n",
    "nombres_variables_numericas = nombres_variables_numericas\n",
    "nombres_variables_categoricas_2_valores = []\n",
    "nombres_variables_categoricas_entre3y6_valores = []\n",
    "nombres_variables_categoricas_masDe6_valores = []\n",
    "for column in nombres_variables_categoricas:\n",
    "    valores = len(pd.unique(autos_sin_missing[column]))\n",
    "    if (valores <=2 ):\n",
    "        nombres_variables_categoricas_2_valores.append(column)\n",
    "    if (valores >2 and valores<=6 ):\n",
    "        nombres_variables_categoricas_entre3y6_valores.append(column)\n",
    "    if(valores >6 ):\n",
    "        nombres_variables_categoricas_masDe6_valores.append(column)\n",
    "\n",
    "print(nombres_variables_numericas)\n",
    "print(nombres_variables_categoricas_2_valores)\n",
    "print(nombres_variables_categoricas_entre3y6_valores)\n",
    "print(nombres_variables_categoricas_masDe6_valores)\n",
    "\n",
    "# Creamos un imput_transformer para cada tipo de variable categorica.\n",
    "\n",
    "categorical_2_imputer_transformer = pipeline.Pipeline([\n",
    "    (\"imputacion por la moda \", SimpleImputer(strategy='most_frequent')),\n",
    "    (\"Codificacion ordinal \", ce.OrdinalEncoder())]\n",
    ")\n",
    "categorical_entre3y6_imputer_transformer = pipeline.Pipeline([\n",
    "    (\"imputacion por la moda \", SimpleImputer(strategy='most_frequent')),\n",
    "    (\"Codificacion one hot encoding \", ce.OneHotEncoder())]\n",
    ")\n",
    "categorical_masDe6_imputer_transformer = pipeline.Pipeline([\n",
    "    (\"imputacion por la moda \", SimpleImputer(strategy='most_frequent')),\n",
    "    (\"Codificacion basada en saldia \", ce.TargetEncoder(smoothing=0.0000001))]\n",
    ")\n",
    "\n",
    "preprocesamiento = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"media\", SimpleImputer(strategy='mean') , nombres_variables_numericas),\n",
    "        (\"Categoricas 2 valores\",categorical_2_imputer_transformer,  nombres_variables_categoricas_2_valores),\n",
    "        (\"Categoricas 3-6 valores\",categorical_entre3y6_imputer_transformer,  nombres_variables_categoricas_entre3y6_valores),\n",
    "        (\"Categoricas mas de 6\", categorical_masDe6_imputer_transformer, nombres_variables_categoricas_masDe6_valores)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Pasamos el preprocesamiento creado a una pipeline.\n",
    "pipe = pipeline.Pipeline([('pre procesamiento ', preprocesamiento), ('minMaxScaler', MinMaxScaler()), ('knn', KNeighborsRegressor()) ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEMA 5: ARBOLES DE DECISION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO SABEMOS SI VAMOS A IMPLEMENTAR ARBOLES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEMA 6: FILTROS Y WRAPPERS (SELECCION DE VARIABLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SELECCION DE LAS K MEJORES VARIABLES ( UTILIZANDO CHI )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listas para almacenar los resultados de accuracy en train y test\n",
    "listaAccTrain = []\n",
    "listaAccTest = []\n",
    "for numVar in [10,20,30]:\n",
    "# <RELLENAR>\n",
    "    # Se llama al constructor que realiza la selección de las k mejores variables con los parámetros apropiados\n",
    "    tecnicaSeleccion = feature_selection.SelectKBest(score_func=feature_selection.chi2, k = numVar)\n",
    "    # Llamada a la función que aprende los parámetros de la selección de variables a partir de los datos de entrenamiento\n",
    "    tecnicaSeleccion =  tecnicaSeleccion.fit(X_train,y_train.Type)\n",
    "    # Llamada a la función que transforma los datos de entrenamiento: realiza la selección de variables\n",
    "    X_train_seleccion = tecnicaSeleccion.transform(X_train)\n",
    "    # Llamada a la función que transforma los datos de test: realiza la selección de variables\n",
    "    X_test_seleccion =  tecnicaSeleccion.transform(X_test)\n",
    "    # Realizamos el proceso para KNN por lo que hay que llamar al constructor de dicho clasificador\n",
    "    knn =  neighbors.KNeighborsClassifier()\n",
    "    # Llamada a la función que realiza el aprendizaje del clasificador\n",
    "    knn =  knn.fit(X_train_seleccion,y_train.Type)\n",
    "    # Llamada a la función que realiza la predicción de los datos de entrenamiento\n",
    "    prediccionTrain =  knn.predict(X_train_seleccion)\n",
    "    # Llamada a la función que calcula el porcentaje de acierto para los datos de entrenamiento\n",
    "    accTrain =  metrics.accuracy_score(y_train,prediccionTrain)*100\n",
    "    # Se añade el resultado a la lista de resultados de train\n",
    "    listaAccTrain.append(accTrain)\n",
    "    print('Seleccionando las {} mejores variables se obtiene un accuracy del {}% en entrenamiento'.format(numVar, accTrain))\n",
    "    # Llamada a la función que realiza la predicción de los datos de test\n",
    "    prediccionTest =  knn.predict(X_test_seleccion)\n",
    "    # Llamada a la función que calcula el porcentaje de acierto para los datos de test\n",
    "    accTest =  metrics.accuracy_score(y_test,prediccionTest)*100\n",
    "    # Se añade el resultado a la lista de resultados de test\n",
    "    listaAccTest.append(accTest)\n",
    "    print('Seleccionando las {} mejores variables se obtiene un accuracy del {}% en test'.format(numVar, accTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listaAccTrain = [] # lista para almancenar el rendimiento de las diferentes posibilidades en train\n",
    "listaAccTest = [] # lista para almancenar el rendimiento de las diferentes posibilidades en test\n",
    "for numVar in [10,20,30]:\n",
    "# <RELLENAR>\n",
    "    # Se llama al constructor que realiza la selección de las k mejores variables con los parámetros apropiados\n",
    "    tecnicaSeleccion = feature_selection.SelectKBest(score_func=feature_selection.f_classif, k = numVar)\n",
    "    # Llamada a la función que aprende los parámetros de la selección de variables a partir de los datos de entrenamiento\n",
    "    tecnicaSeleccion =  tecnicaSeleccion.fit(X_train,y_train.Type)\n",
    "    # Llamada a la función que transforma los datos de entrenamiento: realiza la selección de variables\n",
    "    X_train_seleccion = tecnicaSeleccion.transform(X_train)\n",
    "    # Llamada a la función que transforma los datos de test: realiza la selección de variables\n",
    "    X_test_seleccion =  tecnicaSeleccion.transform(X_test)\n",
    "    # Realizamos el proceso para KNN por lo que hay que llamar al constructor de dicho clasificador\n",
    "    knn =  neighbors.KNeighborsClassifier()\n",
    "    # Llamada a la función que realiza el aprendizaje del clasificador\n",
    "    knn =  knn.fit(X_train_seleccion,y_train.Type)\n",
    "    # Llamada a la función que realiza la predicción de los datos de entrenamiento\n",
    "    prediccionTrain =  knn.predict(X_train_seleccion)\n",
    "    # Llamada a la función que calcula el porcentaje de acierto para los datos de entrenamiento\n",
    "    accTrain =  metrics.accuracy_score(y_train,prediccionTrain)*100\n",
    "    # Se añade el resultado a la lista de resultados de train\n",
    "    listaAccTrain.append(accTrain)\n",
    "    print('Seleccionando las {} mejores variables se obtiene un accuracy del {}% en entrenamiento'.format(numVar, accTrain))\n",
    "    # Llamada a la función que realiza la predicción de los datos de test\n",
    "    prediccionTest =  knn.predict(X_test_seleccion)\n",
    "    # Llamada a la función que calcula el porcentaje de acierto para los datos de test\n",
    "    accTest =  metrics.accuracy_score(y_test,prediccionTest)*100\n",
    "    # Se añade el resultado a la lista de resultados de test\n",
    "    listaAccTest.append(accTest)\n",
    "    print('Seleccionando las {} mejores variables se obtiene un accuracy del {}% en test'.format(numVar, accTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En vez de elegir numero de variables que queremos, ahora metodo del percentil \n",
    "\n",
    "listaAccTrain = [] # lista para almancenar el rendimiento de las diferentes posibilidades en train\n",
    "listaAccTest = [] # lista para almancenar el rendimiento de las diferentes posibilidades en test\n",
    "for numVar in [10,20,30]:\n",
    "# <RELLENAR>\n",
    "    # Se llama al constructor que realiza la selección de las k mejores variables con los parámetros apropiados\n",
    "    tecnicaSeleccion = feature_selection.SelectPercentile(score_func=feature_selection.chi2, percentile = numVar)\n",
    "    # Llamada a la función que aprende los parámetros de la selección de variables a partir de los datos de entrenamiento\n",
    "    tecnicaSeleccion =  tecnicaSeleccion.fit(X_train,y_train.Type)\n",
    "    # Llamada a la función que transforma los datos de entrenamiento: realiza la selección de variables\n",
    "    X_train_seleccion = tecnicaSeleccion.transform(X_train)\n",
    "    # Llamada a la función que transforma los datos de test: realiza la selección de variables\n",
    "    X_test_seleccion =  tecnicaSeleccion.transform(X_test)\n",
    "    # Realizamos el proceso para KNN por lo que hay que llamar al constructor de dicho clasificador\n",
    "    knn =  neighbors.KNeighborsClassifier()\n",
    "    # Llamada a la función que realiza el aprendizaje del clasificador\n",
    "    knn =  knn.fit(X_train_seleccion,y_train.Type)\n",
    "    # Llamada a la función que realiza la predicción de los datos de entrenamiento\n",
    "    prediccionTrain =  knn.predict(X_train_seleccion)\n",
    "    # Llamada a la función que calcula el porcentaje de acierto para los datos de entrenamiento\n",
    "    accTrain =  metrics.accuracy_score(y_train,prediccionTrain)*100\n",
    "    # Se añade el resultado a la lista de resultados de train\n",
    "    listaAccTrain.append(accTrain)\n",
    "    print('Seleccionando las {} mejores variables se obtiene un accuracy del {}% en entrenamiento'.format(numVar, accTrain))\n",
    "    # Llamada a la función que realiza la predicción de los datos de test\n",
    "    prediccionTest =  knn.predict(X_test_seleccion)\n",
    "    # Llamada a la función que calcula el porcentaje de acierto para los datos de test\n",
    "    accTest =  metrics.accuracy_score(y_test,prediccionTest)*100\n",
    "    # Se añade el resultado a la lista de resultados de test\n",
    "    listaAccTest.append(accTest)\n",
    "    print('Seleccionando las {} mejores variables se obtiene un accuracy del {}% en test'.format(numVar, accTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SELECCION DE LAS K MEJORES VARIABLES ( UTILIZANDO ANOVA )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEMA 7: SELECCION DE INSTANCIAS Y MUESTREO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
